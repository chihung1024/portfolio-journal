import os
import time
import json
import logging
from datetime import datetime
from typing import List, Dict, Any, Iterable

import requests
import yfinance as yf
import pandas as pd

# =========================================================================================
# == Python é€±æœ«å®Œæ•´æ ¡é©—è…³æœ¬ å®Œæ•´ç¨‹å¼ç¢¼ (v1.0 - å®Œæ•´è¦†è“‹ç‰ˆ)
# =========================================================================================

# -------------------------------------------------
# 1ï¸âƒ£  è¨­å®š Logging
# -------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s %(levelname)s %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
log = logging.getLogger(__name__)

# -------------------------------------------------
# 2ï¸âƒ£  è®€å–ç’°å¢ƒè®Šæ•¸
# -------------------------------------------------
D1_WORKER_URL   = os.getenv("D1_WORKER_URL")
D1_API_KEY      = os.getenv("D1_API_KEY")
GCP_API_URL     = os.getenv("GCP_API_URL")
INTERNAL_API_KEY = os.getenv("INTERNAL_API_KEY")   # åªçµ¦ GCP é‡ç®—æœå‹™çš„é‡‘é‘°

if not D1_WORKER_URL or not D1_API_KEY:
    raise RuntimeError("å¿…é ˆè¨­å®š D1_WORKER_URL ä»¥åŠ D1_API_KEY")
if not GCP_API_URL:
    raise RuntimeError("å¿…é ˆè¨­å®š GCP_API_URL")
if not INTERNAL_API_KEY:
    raise RuntimeError("å¿…é ˆè¨­å®š INTERNAL_API_KEY (GitHub Actions secret)")

# -------------------------------------------------
# 3ï¸âƒ£  D1 çš„é€šç”¨æŸ¥è©¢ / æ‰¹æ¬¡å‡½å¼
# -------------------------------------------------
def d1_query(sql: str, params: List[Any] = None) -> List[Dict[str, Any]]:
    """å‘ D1_worker /query ç™¼é€ SQLï¼Œå›å‚³çµæœé™£åˆ—ï¼ˆlist of dictï¼‰"""
    if params is None:
        params = []
    headers = {"X-API-KEY": D1_API_KEY, "Content-Type": "application/json"}
    try:
        resp = requests.post(
            f"{D1_WORKER_URL}/query",
            json={"sql": sql, "params": params},
            headers=headers,
            timeout=15,
        )
        resp.raise_for_status()
        return resp.json().get("results", [])
    except requests.RequestException as exc:
        log.error("D1 query å¤±æ•—: %s", exc, exc_info=True)
        return []

def d1_batch(statements: List[Dict[str, Any]]) -> bool:
    """å‘ D1_worker /batch å¯¦ä½œå¤šç­† SQLï¼Œå›å‚³æˆåŠŸ/å¤±æ•—å¸ƒæ—å€¼"""
    headers = {"X-API-KEY": D1_API_KEY, "Content-Type": "application/json"}
    try:
        resp = requests.post(
            f"{D1_WORKER_URL}/batch",
            json={"statements": statements},
            headers=headers,
            timeout=30,
        )
        resp.raise_for_status()
        return True
    except requests.RequestException as exc:
        log.error("D1 batch å¤±æ•—: %s", exc, exc_info=True)
        return False

# -------------------------------------------------
# 4ï¸âƒ£  å–å¾—éœ€è¦å®Œæ•´åˆ·æ–°çš„æ¨™çš„èˆ‡æ´»èº uid
# -------------------------------------------------
def get_full_refresh_targets() -> (List[Dict[str, Any]], List[int]):
    """å›å‚³å…©å€‹åˆ—è¡¨ï¼š<br> 1. market_data_coverage ä¸­çš„ {symbol, earliest_date} <br> 2. æ‰€æœ‰æ´»èºä½¿ç”¨è€… uid"""
    log.info("å¾ market_data_coverage å–å¾—åˆ·æ–°ç›®æ¨™...")
    # 1ï¸âƒ£ å–å¾—æ¨™çš„
    sql_targets = "SELECT symbol, earliest_date FROM market_data_coverage"
    targets = d1_query(sql_targets)

    # 2ï¸âƒ£ å–å¾—æ´»èº uidï¼ˆdistinctï¼‰
    sql_uids = "SELECT DISTINCT uid FROM transactions"
    uid_rows = d1_query(sql_uids)
    uids = [row["uid"] for row in uid_rows if row.get("uid")]

    log.info("æ‰¾åˆ° %d å€‹éœ€å®Œæ•´åˆ·æ–°çš„æ¨™çš„", len(targets))
    log.info("æ‰¾åˆ° %d ä½æ´»èºä½¿ç”¨è€…", len(uids))
    return targets, uids

# -------------------------------------------------
# 5ï¸âƒ£  æŠ“å–æ­·å²è³‡æ–™ã€è¦†å¯« D1
# -------------------------------------------------
def fetch_and_overwrite_market_data(targets: List[Dict[str, Any]]) -> None:
    """é‡å°æ¯æ”¯æ¨™çš„æŠ“å–å®Œæ•´æ­·å²ï¼Œåˆªé™¤èˆŠè³‡æ–™ã€æ’å…¥æ–°è³‡æ–™"""
    if not targets:
        log.warning("æ²’æœ‰éœ€è¦åˆ·æ–°çš„æ¨™çš„")
        return

    today_str = datetime.now().strftime("%Y-%m-%d")

    for target in targets:
        symbol = target.get("symbol")
        start_date = target.get("earliest_date")
        if not symbol or not start_date:
            continue

        log.info("--- æ­£åœ¨åˆ·æ–° %s (è‡ª %s) ---", symbol, start_date)

        is_fx = "=" in symbol                    # ç°¡æ˜“åˆ¤æ–·æ˜¯å¦ç‚ºå¤–åŒ¯ (symbol å…§æœ‰ = ç¬¦è™Ÿ)
        price_table = "exchange_rates" if is_fx else "price_history"

        max_retries = 3
        for attempt in range(1, max_retries + 1):
            try:
                ticker = yf.Ticker(symbol)
                hist = ticker.history(
                    start=start_date,
                    interval="1d",
                    auto_adjust=False,
                    back_adjust=False,
                )
                if hist.empty:
                    log.warning("æ‰¾ä¸åˆ° %s å¾ %s èµ·çš„è³‡æ–™ï¼Œè·³é", symbol, start_date)
                    break

                log.info("æŠ“åˆ° %d ç­† %s æ­·å²è³‡æ–™", len(hist), symbol)

                # ---------- æº–å‚™ SQL ----------
                ops: List[Dict[str, Any]] = []

                # åˆªé™¤èˆŠè³‡æ–™
                ops.append(
                    {"sql": f"DELETE FROM {price_table} WHERE symbol = ?", "params": [symbol]}
                )
                if not is_fx:
                    ops.append({"sql": "DELETE FROM dividend_history WHERE symbol = ?", "params": [symbol]})

                # æ’å…¥æ–°è³‡æ–™
                for dt, row in hist.iterrows():
                    date_str = dt.strftime("%Y-%m-%d")
                    if pd.notna(row["Close"]):
                        ops.append(
                            {
                                "sql": f"INSERT INTO {price_table} (symbol, date, price) VALUES (?, ?, ?)",
                                "params": [symbol, date_str, float(row["Close"])],
                            }
                        )
                    # è‹¥æ˜¯è‚¡ç¥¨ä¸”æœ‰è‚¡æ¯
                    if not is_fx and row.get("Dividends", 0) > 0:
                        ops.append(
                            {
                                "sql": "INSERT INTO dividend_history (symbol, date, dividend) VALUES (?, ?, ?)",
                                "params": [symbol, date_str, float(row["Dividends"])],
                            }
                        )

                # åŸ·è¡Œæ‰¹æ¬¡
                if d1_batch(ops):
                    log.info("æˆåŠŸè¦†è“‹ %s çš„è³‡æ–™åˆ° D1", symbol)
                else:
                    log.error("è¦†å¯« %s åˆ° D1 å¤±æ•—", symbol)

                # æ›´æ–° market_data_coverage çš„ last_updated
                d1_query(
                    "UPDATE market_data_coverage SET last_updated = ? WHERE symbol = ?",
                    [today_str, symbol],
                )
                # è‹¥æˆåŠŸï¼Œç›´æ¥è·³å‡º retry è¿´åœˆ
                break

            except Exception as exc:
                log.exception("ç¬¬ %d æ¬¡å˜—è©¦æŠ“å– %s æ™‚ç™¼ç”Ÿä¾‹å¤–", attempt, symbol)
                if attempt < max_retries:
                    log.info("5 ç§’å¾Œé‡è©¦...")
                    time.sleep(5)
                else:
                    log.error("é€£çºŒ %d æ¬¡æŠ“å–å¤±æ•—ï¼Œæ”¾æ£„ %s", max_retries, symbol)

# -------------------------------------------------
# 6ï¸âƒ£  å–®ç­†è§¸ç™¼é‡æ–°è¨ˆç®— (debug å»ºè­°)
# -------------------------------------------------
def trigger_recalculation(uid: str) -> bool:
    """å‘ GCP Cloud Function è§¸ç™¼å–®ç­†ä½¿ç”¨è€…çš„æŠ•è³‡çµ„åˆé‡æ–°è¨ˆç®—"""
    if not uid:
        log.warning("uid ç‚ºç©ºï¼Œè·³é")
        return False

    payload = {
        "action": "recalculate",
        "data": {"uid": uid},
    }
    headers = {
        "Content-Type": "application/json",
        "x-internal-key": INTERNAL_API_KEY,
    }

    try:
        resp = requests.post(GCP_API_URL, json=payload, headers=headers, timeout=10)
        if resp.status_code == 200:
            log.info("âœ… æˆåŠŸè§¸ç™¼ UID %s çš„é‡ç®—", uid)
            return True
        else:
            log.warning(
                "âŒ è§¸ç™¼é‡ç®—å¤±æ•—: uid=%s, status=%s, body=%s",
                uid,
                resp.status_code,
                resp.text,
            )
            return False
    except requests.RequestException as exc:
        log.error("ğŸš¨ è«‹æ±‚ä¾‹å¤– (uid=%s): %s", uid, exc, exc_info=True)
        return False

# -------------------------------------------------
# 7ï¸âƒ£  æ‰¹æ¬¡å‘¼å«ï¼ˆéæ­·ç‰ˆï¼‰
# -------------------------------------------------
def trigger_recalculations(uids: Iterable[str]) -> None:
    """éæ­· all_uidsï¼Œå°æ¯ç­†å‘¼å« trigger_recalculation ä¸¦çµ±è¨ˆçµæœ"""
    if not uids:
        log.info("æ²’æœ‰ä½¿ç”¨è€…éœ€è¦è§¸ç™¼é‡ç®—")
        return

    uids = list(uids)  # è®“æˆ‘å€‘å¯ä»¥å–å¾—é•·åº¦ã€åš index åˆ¤æ–·
    log.info("=== æº–å‚™ç‚º %d ä½ä½¿ç”¨è€…è§¸ç™¼é‡ç®— ===", len(uids))

    success, failed = 0, 0
    for idx, uid in enumerate(uids, start=1):
        if trigger_recalculation(uid):
            success += 1
        else:
            failed += 1

        # é˜²æ­¢çŸ­æ™‚é–“å…§ç™¼å¤ªå¤šè«‹æ±‚ï¼ˆä¿ç•™åŸæœ¬çš„ 1 ç§’é–“éš”ï¼‰
        if idx < len(uids):
            time.sleep(1)

    log.info("=== è§¸ç™¼å®Œç•¢ï¼šæˆåŠŸ %d / å¤±æ•— %d ===", success, failed)

# -------------------------------------------------
# 8ï¸âƒ£  ç¨‹å¼å…¥å£
# -------------------------------------------------
if __name__ == "__main__":
    log.info("=== é–‹å§‹åŸ·è¡Œé€±æœ«å¸‚å ´è³‡æ–™å®Œæ•´æ ¡é©—è…³æœ¬ (v1.0) ===")
    refresh_targets, all_uids = get_full_refresh_targets()

    if refresh_targets:
        fetch_and_overwrite_market_data(refresh_targets)
        trigger_recalculations(all_uids)
    else:
        log.info("market_data_coverage è¡¨ä¸­æ²’æœ‰éœ€è¦åˆ·æ–°çš„æ¨™çš„")

    log.info("=== é€±æœ«å¸‚å ´è³‡æ–™å®Œæ•´æ ¡é©—è…³æœ¬åŸ·è¡ŒçµæŸ ===")
